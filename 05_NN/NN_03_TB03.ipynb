{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TENSORBOARD USED\n",
    "- tensorboard --logdir =./logs\n",
    "- more DeeeeeeeeeeP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 2], name='x-input')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name='y-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"layer1\") as scope:\n",
    "    W1 = tf.Variable(tf.random_normal([2,5]),name=\"Weight_one\")\n",
    "    b1 = tf.Variable(tf.random_normal([5]),name=\"Bias_one\")\n",
    "    layer_one = tf.sigmoid(tf.matmul(X,W1) + b1)\n",
    "    \n",
    "    w1_histogram = tf.summary.histogram(\"Weight_one\", W1)\n",
    "    b1_histogram = tf.summary.histogram(\"Bias-one\",b1)\n",
    "    layer_one_histogram = tf.summary.histogram(\"layer1\",layer_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## more Deep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"layer2\") as scope:\n",
    "    W2 = tf.Variable(tf.random_normal([5,5]),name=\"Weight_two\")\n",
    "    b2 = tf.Variable(tf.random_normal([5]),name=\"Bias_two\")\n",
    "    layer_two = tf.sigmoid(tf.matmul(layer_one,W2) + b2)\n",
    "    \n",
    "    w2_histogram = tf.summary.histogram(\"Weight_two\", W2)\n",
    "    b2_histogram = tf.summary.histogram(\"Bias_two\",b2)\n",
    "    layer_two_histogram = tf.summary.histogram(\"layer2\",layer_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"layer3\") as scope:\n",
    "    W3 = tf.Variable(tf.random_normal([5,5]),name=\"Weight_three\")\n",
    "    b3 = tf.Variable(tf.random_normal([5]),name=\"Bias_three\")\n",
    "    layer_three = tf.sigmoid(tf.matmul(layer_two,W3) + b3)\n",
    "    \n",
    "    w3_histogram = tf.summary.histogram(\"Weight_three\", W3)\n",
    "    b3_histogram = tf.summary.histogram(\"Bias_three\",b3)\n",
    "    layer_three_histogram = tf.summary.histogram(\"layer3\",layer_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"layer4\") as scope:\n",
    "    W4 = tf.Variable(tf.random_normal([5,5]),name=\"Weight_four\")\n",
    "    b4 = tf.Variable(tf.random_normal([5]),name=\"Bias_four\")\n",
    "    layer_four = tf.sigmoid(tf.matmul(layer_three,W4) + b4)\n",
    "    \n",
    "    w4_histogram = tf.summary.histogram(\"Weight_four\", W4)\n",
    "    b4_histogram = tf.summary.histogram(\"Bias_four\",b4)\n",
    "    layer_two_histogram = tf.summary.histogram(\"layer4\",layer_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"layer5\") as scope:\n",
    "    W5 = tf.Variable(tf.random_normal([5,5]),name=\"Weight_five\")\n",
    "    b5 = tf.Variable(tf.random_normal([5]),name=\"Bias_five\")\n",
    "    layer_five = tf.sigmoid(tf.matmul(layer_four,W5) + b5)\n",
    "    \n",
    "    w5_histogram = tf.summary.histogram(\"Weight_five\", W5)\n",
    "    b5_histogram = tf.summary.histogram(\"Bias_five\",b5)\n",
    "    layer_five_histogram = tf.summary.histogram(\"layer_five\",layer_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"layer6\") as scope:\n",
    "    W6 = tf.Variable(tf.random_normal([5,5]),name=\"Weight_six\")\n",
    "    b6 = tf.Variable(tf.random_normal([5]),name=\"Bias_six\")\n",
    "    layer_six = tf.sigmoid(tf.matmul(layer_five,W6) + b6)\n",
    "    \n",
    "    w6_histogram = tf.summary.histogram(\"Weight_six\", W6)\n",
    "    b6_histogram = tf.summary.histogram(\"Bias_six\",b6)\n",
    "    layer_six_histogram = tf.summary.histogram(\"layer_six\",layer_six)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"layer7\") as scope:\n",
    "    W7 = tf.Variable(tf.random_normal([5,5]),name=\"Weight_seven\")\n",
    "    b7 = tf.Variable(tf.random_normal([5]),name=\"Bias_seven\")\n",
    "    layer_seven = tf.sigmoid(tf.matmul(layer_six, W7) + b7)\n",
    "    \n",
    "    w7_histogram = tf.summary.histogram(\"Weight_seven\", W7)\n",
    "    b7_histogram = tf.summary.histogram(\"Bias_seven\",b7)\n",
    "    layer_seven_histogram = tf.summary.histogram(\"layer_seven\",layer_seven)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"layer8\") as scope:\n",
    "    W8 = tf.Variable(tf.random_normal([5,5]),name=\"Weight_eight\")\n",
    "    b8 = tf.Variable(tf.random_normal([5]),name=\"Bias_eight\")\n",
    "    layer_eight = tf.sigmoid(tf.matmul(layer_seven, W8) + b8)\n",
    "    \n",
    "    w8_histogram = tf.summary.histogram(\"Weight_eight\", W8)\n",
    "    b8_histogram = tf.summary.histogram(\"Bias_eight\",b8)\n",
    "    layer_eight_histogram = tf.summary.histogram(\"layer_eight\",layer_eight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"layer9\") as scope:\n",
    "    W9 = tf.Variable(tf.random_normal([5,5]),name=\"Weight_nine\")\n",
    "    b9 = tf.Variable(tf.random_normal([5]),name=\"Bias_nine\")\n",
    "    layer_nine = tf.sigmoid(tf.matmul(layer_eight, W9) + b9)\n",
    "    \n",
    "    w9_histogram = tf.summary.histogram(\"Weight_nine\", W9)\n",
    "    b9_histogram = tf.summary.histogram(\"Bias-nine\", b9)\n",
    "    layer_nine_histogram = tf.summary.histogram(\"layer_nine\", layer_nine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"layer10\") as scope:\n",
    "    W10 = tf.Variable(tf.random_normal([5,5]),name=\"Weight_ten\")\n",
    "    b10 = tf.Variable(tf.random_normal([5]),name=\"Bias_ten\")\n",
    "    layer_ten = tf.sigmoid(tf.matmul(layer_nine, W10) + b10)\n",
    "    \n",
    "    w10_histogram = tf.summary.histogram(\"Weight_ten\", W10)\n",
    "    b10_histogram = tf.summary.histogram(\"Bias_ten\",b10)\n",
    "    layer_ten_histogram = tf.summary.histogram(\"layer_ten\",layer_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"last\") as scope:\n",
    "    W11 = tf.Variable(tf.random_normal([5,2]),name=\"Weight_11\")\n",
    "    b11 = tf.Variable(tf.random_normal([2]),name=\"Bias_11\")\n",
    "    Hypothesis = tf.sigmoid(tf.matmul(layer_ten, W11) + b11)\n",
    "    layer_two_histogram = tf.summary.histogram(\"Hypothesis\",Hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"cost\") as scope:\n",
    "    cost = -tf.reduce_mean(Y * tf.log(Hypothesis) + (1 - Y) * tf.log(1 - Hypothesis))\n",
    "    cost_summ = tf.summary.scalar(\"cost\", cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR 변경 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\") as scope:\n",
    "    train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = tf.cast(Hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "accuracy_summ = tf.summary.scalar(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_summary = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"\\\\xor_logs_03\")\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.812758 [array([[-0.16147956,  0.24957962, -0.66619468,  0.42758837,  0.64626682],\n",
      "       [-0.84341097,  1.46398091, -0.26762256, -0.14369723, -1.15831685]], dtype=float32), array([[-1.16403198,  0.78800523,  0.35485393, -2.27612066, -0.92510074],\n",
      "       [ 1.15226865, -0.66218024, -1.0779742 , -1.25341713,  1.53692174],\n",
      "       [ 0.64518398, -2.04512215, -0.72257191,  0.74833518, -0.11714398],\n",
      "       [ 1.28935122, -1.12702823,  0.65113622, -0.3444469 , -0.03775107],\n",
      "       [ 1.42454088,  1.86463809,  1.14406264,  1.38350153, -1.29012299]], dtype=float32)]\n",
      "500 0.693148 [array([[-0.16145404,  0.24960656, -0.66619468,  0.42757264,  0.64621019],\n",
      "       [-0.84343392,  1.46398044, -0.26762292, -0.14369127, -1.15831542]], dtype=float32), array([[-1.16403198,  0.7880075 ,  0.35483494, -2.27612066, -0.92510515],\n",
      "       [ 1.15226865, -0.66217887, -1.0779773 , -1.25341713,  1.53691876],\n",
      "       [ 0.64518219, -2.04511976, -0.72257984,  0.74835706, -0.11715176],\n",
      "       [ 1.28935087, -1.12702465,  0.65110004, -0.34444967, -0.03776633],\n",
      "       [ 1.42454004,  1.86464131,  1.14399934,  1.38349855, -1.29013109]], dtype=float32)]\n",
      "1000 0.693148 [array([[-0.16143169,  0.24963637, -0.66619468,  0.42755774,  0.64615059],\n",
      "       [-0.84346372,  1.46398044, -0.26762292, -0.14368382, -1.15831542]], dtype=float32), array([[-1.16403198,  0.7880075 ,  0.35482004, -2.27612066, -0.92510515],\n",
      "       [ 1.15226865, -0.66217887, -1.0779773 , -1.25341713,  1.53691876],\n",
      "       [ 0.64518219, -2.04511976, -0.72257984,  0.74838686, -0.11715176],\n",
      "       [ 1.28935087, -1.12702465,  0.65107024, -0.34444967, -0.03777378],\n",
      "       [ 1.42454004,  1.86464131,  1.14393973,  1.38349855, -1.29013109]], dtype=float32)]\n",
      "1500 0.693148 [array([[-0.16140933,  0.24966617, -0.66619468,  0.42754284,  0.64609098],\n",
      "       [-0.84349352,  1.46398044, -0.26762292, -0.14367637, -1.15831542]], dtype=float32), array([[-1.16403198,  0.7880075 ,  0.35480514, -2.27612066, -0.92510515],\n",
      "       [ 1.15226865, -0.66217887, -1.0779773 , -1.25341713,  1.53691876],\n",
      "       [ 0.64518219, -2.04511976, -0.72257984,  0.74841666, -0.11715176],\n",
      "       [ 1.28935087, -1.12702465,  0.65104043, -0.34444967, -0.03778123],\n",
      "       [ 1.42454004,  1.86464131,  1.14388013,  1.38349855, -1.29013109]], dtype=float32)]\n",
      "2000 0.693148 [array([[-0.16138698,  0.24969597, -0.66619468,  0.42752793,  0.64603138],\n",
      "       [-0.84352332,  1.46398044, -0.26762292, -0.14366892, -1.15831542]], dtype=float32), array([[-1.16403198,  0.7880075 ,  0.35479024, -2.27612066, -0.92510515],\n",
      "       [ 1.15226865, -0.66217887, -1.0779773 , -1.25341713,  1.53691876],\n",
      "       [ 0.64518219, -2.04511976, -0.72257984,  0.74844646, -0.11715176],\n",
      "       [ 1.28935087, -1.12702465,  0.65101063, -0.34444967, -0.03778868],\n",
      "       [ 1.42454004,  1.86464131,  1.14382052,  1.38349855, -1.29013109]], dtype=float32)]\n",
      "2500 0.693148 [array([[-0.16136463,  0.24972577, -0.66619468,  0.42751303,  0.64597178],\n",
      "       [-0.84355313,  1.46398044, -0.26762292, -0.14366147, -1.15831542]], dtype=float32), array([[-1.16403198,  0.7880075 ,  0.35477534, -2.27612066, -0.92510515],\n",
      "       [ 1.15226865, -0.66217887, -1.0779773 , -1.25341713,  1.53691876],\n",
      "       [ 0.64518219, -2.04511976, -0.72257984,  0.74847627, -0.11715176],\n",
      "       [ 1.28935087, -1.12702465,  0.65098083, -0.34444967, -0.03779613],\n",
      "       [ 1.42454004,  1.86464131,  1.14376092,  1.38349855, -1.29013109]], dtype=float32)]\n",
      "3000 0.693148 [array([[-0.16134228,  0.24975558, -0.66619468,  0.42749813,  0.64591217],\n",
      "       [-0.84358293,  1.46398044, -0.26762292, -0.14365402, -1.15831542]], dtype=float32), array([[-1.16403198,  0.7880075 ,  0.35476044, -2.27612066, -0.92510515],\n",
      "       [ 1.15226865, -0.66217887, -1.0779773 , -1.25341713,  1.53691876],\n",
      "       [ 0.64518219, -2.04511976, -0.72257984,  0.74850607, -0.11715176],\n",
      "       [ 1.28935087, -1.12702465,  0.65095103, -0.34444967, -0.03780358],\n",
      "       [ 1.42454004,  1.86464131,  1.14370131,  1.38349855, -1.29013109]], dtype=float32)]\n",
      "3500 0.693148 [array([[-0.16131993,  0.24978538, -0.66619468,  0.42748323,  0.64585257],\n",
      "       [-0.84361273,  1.46398044, -0.26762292, -0.14364657, -1.15831542]], dtype=float32), array([[-1.16403198,  0.7880075 ,  0.35474554, -2.27612066, -0.92510515],\n",
      "       [ 1.15226865, -0.66217887, -1.0779773 , -1.25341713,  1.53691876],\n",
      "       [ 0.64518219, -2.04511976, -0.72257984,  0.74853587, -0.11715176],\n",
      "       [ 1.28935087, -1.12702465,  0.65092123, -0.34444967, -0.03781103],\n",
      "       [ 1.42454004,  1.86464131,  1.14364171,  1.38349855, -1.29013109]], dtype=float32)]\n",
      "4000 0.693148 [array([[-0.16129757,  0.24981518, -0.66619468,  0.42746833,  0.64579296],\n",
      "       [-0.84364253,  1.46398044, -0.26762292, -0.14363912, -1.15831542]], dtype=float32), array([[-1.16403198,  0.7880075 ,  0.35473064, -2.27612066, -0.92510515],\n",
      "       [ 1.15226865, -0.66217887, -1.0779773 , -1.25341713,  1.53691876],\n",
      "       [ 0.64518219, -2.04511976, -0.72257984,  0.74856567, -0.11715176],\n",
      "       [ 1.28935087, -1.12702465,  0.65089142, -0.34444967, -0.03781848],\n",
      "       [ 1.42454004,  1.86464131,  1.14358211,  1.38349855, -1.29013109]], dtype=float32)]\n",
      "4500 0.693148 [array([[-0.16127522,  0.24984498, -0.66619468,  0.42745343,  0.64573336],\n",
      "       [-0.84367234,  1.46398044, -0.26762292, -0.14363167, -1.15831542]], dtype=float32), array([[-1.16403198,  0.7880075 ,  0.35471573, -2.27612066, -0.92510515],\n",
      "       [ 1.15226865, -0.66217887, -1.0779773 , -1.25341713,  1.53691876],\n",
      "       [ 0.64518219, -2.04511976, -0.72257984,  0.74859548, -0.11715176],\n",
      "       [ 1.28935087, -1.12702465,  0.65086162, -0.34444967, -0.03782593],\n",
      "       [ 1.42454004,  1.86464131,  1.1435225 ,  1.38349855, -1.29013109]], dtype=float32)]\n",
      "5000 0.693148 [array([[-0.16125287,  0.24987479, -0.66619468,  0.42743853,  0.64567375],\n",
      "       [-0.84370214,  1.46398044, -0.26762292, -0.14362422, -1.15831542]], dtype=float32), array([[-1.16403198,  0.7880075 ,  0.35470083, -2.27612066, -0.92510515],\n",
      "       [ 1.15226865, -0.66217887, -1.0779773 , -1.25341713,  1.53691876],\n",
      "       [ 0.64518219, -2.04511976, -0.72257984,  0.74862528, -0.11715176],\n",
      "       [ 1.28935087, -1.12702465,  0.65083182, -0.34444967, -0.03783338],\n",
      "       [ 1.42454004,  1.86464131,  1.1434629 ,  1.38349855, -1.29013109]], dtype=float32)]\n",
      "5500 0.693148 [array([[-0.16123052,  0.24990459, -0.66619468,  0.42742363,  0.64561415],\n",
      "       [-0.84373194,  1.46398044, -0.26762292, -0.14361677, -1.15831542]], dtype=float32), array([[-1.16403198,  0.7880075 ,  0.35468593, -2.27612066, -0.92510515],\n",
      "       [ 1.15226865, -0.66217887, -1.0779773 , -1.25341713,  1.53691876],\n",
      "       [ 0.64518219, -2.04511976, -0.72257984,  0.74865508, -0.11715176],\n",
      "       [ 1.28935087, -1.12702465,  0.65080202, -0.34444967, -0.03784083],\n",
      "       [ 1.42454004,  1.86464131,  1.14340329,  1.38349855, -1.29013109]], dtype=float32)]\n",
      "6000 0.693148 [array([[-0.16120817,  0.24993439, -0.66619468,  0.42740873,  0.64555454],\n",
      "       [-0.84376174,  1.46398044, -0.26762292, -0.14360932, -1.15831542]], dtype=float32), array([[-1.16403198,  0.7880075 ,  0.35467103, -2.27612066, -0.92510515],\n",
      "       [ 1.15226865, -0.66217887, -1.0779773 , -1.25341713,  1.53691876],\n",
      "       [ 0.64518219, -2.04511976, -0.72257984,  0.74868488, -0.11715176],\n",
      "       [ 1.28935087, -1.12702465,  0.65077221, -0.34444967, -0.03784828],\n",
      "       [ 1.42454004,  1.86464131,  1.14334369,  1.38349855, -1.29013109]], dtype=float32)]\n",
      "6500 0.693148 [array([[-0.16118582,  0.24996419, -0.66619468,  0.42739382,  0.64549494],\n",
      "       [-0.84379154,  1.46398044, -0.26762292, -0.14360186, -1.15831542]], dtype=float32), array([[-1.16403198,  0.7880075 ,  0.35465613, -2.27612066, -0.92510515],\n",
      "       [ 1.15226865, -0.66217887, -1.0779773 , -1.25341713,  1.53691876],\n",
      "       [ 0.64518219, -2.04511976, -0.72257984,  0.74871469, -0.11715176],\n",
      "       [ 1.28935087, -1.12702465,  0.65074241, -0.34444967, -0.03785573],\n",
      "       [ 1.42454004,  1.86464131,  1.14328408,  1.38349855, -1.29013109]], dtype=float32)]\n",
      "7000 0.693148 [array([[-0.16116346,  0.24999399, -0.66619468,  0.42737892,  0.64543533],\n",
      "       [-0.84382135,  1.46398044, -0.26762292, -0.14359441, -1.15831542]], dtype=float32), array([[-1.16403198,  0.7880075 ,  0.35464123, -2.27612066, -0.92510515],\n",
      "       [ 1.15226865, -0.66217887, -1.0779773 , -1.25341713,  1.53691876],\n",
      "       [ 0.64518219, -2.04511976, -0.72257984,  0.74874449, -0.11715176],\n",
      "       [ 1.28935087, -1.12702465,  0.65071261, -0.34444967, -0.03786318],\n",
      "       [ 1.42454004,  1.86464131,  1.14322448,  1.38349855, -1.29013109]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500 0.693148 [array([[-0.16114111,  0.25002378, -0.66619468,  0.42736402,  0.64537573],\n",
      "       [-0.84385115,  1.46398044, -0.26762292, -0.14358696, -1.15831542]], dtype=float32), array([[-1.16403198,  0.7880075 ,  0.35462633, -2.27612066, -0.92510515],\n",
      "       [ 1.15226865, -0.66217887, -1.0779773 , -1.25341713,  1.53691876],\n",
      "       [ 0.64518219, -2.04511976, -0.72257984,  0.74877429, -0.11715176],\n",
      "       [ 1.28935087, -1.12702465,  0.65068281, -0.34444967, -0.03787063],\n",
      "       [ 1.42454004,  1.86464131,  1.14316487,  1.38349855, -1.29013109]], dtype=float32)]\n",
      "8000 0.693148 [array([[-0.16111876,  0.25005358, -0.66619468,  0.42734912,  0.64531612],\n",
      "       [-0.84388095,  1.46398044, -0.26762292, -0.14357951, -1.15831542]], dtype=float32), array([[-1.16403198,  0.7880075 ,  0.35461143, -2.27612066, -0.92510515],\n",
      "       [ 1.15226865, -0.66217887, -1.0779773 , -1.25341713,  1.53691876],\n",
      "       [ 0.64518219, -2.04511976, -0.72257984,  0.74880409, -0.11715176],\n",
      "       [ 1.28935087, -1.12702465,  0.650653  , -0.34444967, -0.03787808],\n",
      "       [ 1.42454004,  1.86464131,  1.14310527,  1.38349855, -1.29013109]], dtype=float32)]\n",
      "8500 0.693148 [array([[-0.16109641,  0.25008339, -0.66619468,  0.42733422,  0.64525652],\n",
      "       [-0.84391075,  1.46398044, -0.26762292, -0.14357206, -1.15831542]], dtype=float32), array([[-1.16403198,  0.7880075 ,  0.35459653, -2.27612066, -0.92510515],\n",
      "       [ 1.15226865, -0.66217887, -1.0779773 , -1.25341713,  1.53691876],\n",
      "       [ 0.64518219, -2.04511976, -0.72257984,  0.74883389, -0.11715176],\n",
      "       [ 1.28935087, -1.12702465,  0.6506232 , -0.34444967, -0.03788554],\n",
      "       [ 1.42454004,  1.86464131,  1.14304566,  1.38349855, -1.29013109]], dtype=float32)]\n",
      "9000 0.693148 [array([[-0.16107406,  0.25011319, -0.66619468,  0.42731932,  0.64519691],\n",
      "       [-0.84394056,  1.46398044, -0.26762292, -0.14356461, -1.15831542]], dtype=float32), array([[-1.16403198,  0.7880075 ,  0.35458162, -2.27612066, -0.92510515],\n",
      "       [ 1.15226865, -0.66217887, -1.0779773 , -1.25341713,  1.53691876],\n",
      "       [ 0.64518219, -2.04511976, -0.72257984,  0.7488637 , -0.11715176],\n",
      "       [ 1.28935087, -1.12702465,  0.6505934 , -0.34444967, -0.03789299],\n",
      "       [ 1.42454004,  1.86464131,  1.14298606,  1.38349855, -1.29013109]], dtype=float32)]\n",
      "9500 0.693148 [array([[-0.16105171,  0.25014299, -0.66619468,  0.42730442,  0.64513731],\n",
      "       [-0.84397036,  1.46398044, -0.26762292, -0.14355716, -1.15831542]], dtype=float32), array([[-1.16403198,  0.7880075 ,  0.35456672, -2.27612066, -0.92510515],\n",
      "       [ 1.15226865, -0.66217887, -1.0779773 , -1.25341713,  1.53691876],\n",
      "       [ 0.64518219, -2.04511976, -0.72257984,  0.7488935 , -0.11715176],\n",
      "       [ 1.28935087, -1.12702465,  0.6505636 , -0.34444967, -0.03790044],\n",
      "       [ 1.42454004,  1.86464131,  1.14292645,  1.38349855, -1.29013109]], dtype=float32)]\n",
      "10000 0.693148 [array([[-0.16102935,  0.25017279, -0.66619468,  0.42728952,  0.64507771],\n",
      "       [-0.84400016,  1.46398044, -0.26762292, -0.14354971, -1.15831542]], dtype=float32), array([[-1.16403198,  0.7880075 ,  0.35455182, -2.27612066, -0.92510515],\n",
      "       [ 1.15226865, -0.66217887, -1.0779773 , -1.25341713,  1.53691876],\n",
      "       [ 0.64518219, -2.04511976, -0.72257984,  0.7489233 , -0.11715176],\n",
      "       [ 1.28935087, -1.12702465,  0.6505338 , -0.34444967, -0.03790789],\n",
      "       [ 1.42454004,  1.86464131,  1.14286685,  1.38349855, -1.29013109]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "        summary, _ = sess.run([merged_summary, train], feed_dict={X: x_data, Y: y_data})\n",
    "        writer.add_summary(summary, global_step=step)\n",
    "\n",
    "        if step % 500 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hypothesis:  [[ 0.50000006  0.49999857]\n",
      " [ 0.49999666  0.49999964]\n",
      " [ 0.50000173  0.49999976]\n",
      " [ 0.5         0.50000244]] \n",
      "Correct:  [[ 1.  0.]\n",
      " [ 0.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]] \n",
      "Accuracy:  0.375\n"
     ]
    }
   ],
   "source": [
    "h, c, a = sess.run([Hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- XOR의 경우 DeeeeeeP하게 Net를 구성해도 정확도가 떨어지는 결과를 도출함.(VANISHING GRADIENT)\n",
    "- 90% 이상의 정확도가 나와야 신뢰성을 기반으로 사용할 수 있는 알고리즘이 된다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
